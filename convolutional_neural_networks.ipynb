{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    # Resize images from 28x28 to 32x32 to match LeNet-5's expected input dimensions\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize images to match LeNet-5's expected input distribution (mean=0.5, std=0.5)\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the test data\n",
    "testset = datasets.MNIST('pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # Define the convolutional layers\n",
    "        # Assuming input is 1 channel (grayscale)\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)  \n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        # The 6*6 comes from the dimension reduction of input image through conv and pooling layers\n",
    "        self.fc1 = nn.Linear(16*6*6, 120)  \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Assuming 10 output classes (digits 0-9)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolution, followed by pooling, then ReLU activation\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        # Apply the second convolution, followed by pooling, then ReLU activation\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        # Flatten the tensor for the fully connected layer\n",
    "        x = x.view(-1, 16*6*6)\n",
    "        # Apply the first fully connected layer with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply the second fully connected layer with ReLU activation\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # Apply the third fully connected layer to get the class scores\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Loss: 2.138032580553\n",
      "Epoch  2, Loss: 0.359664186843\n",
      "Epoch  3, Loss: 0.170584919484\n",
      "Epoch  4, Loss: 0.123416796011\n",
      "Epoch  5, Loss: 0.099806052965\n",
      "Epoch  6, Loss: 0.086629401974\n",
      "Epoch  7, Loss: 0.076796694015\n",
      "Epoch  8, Loss: 0.068962281645\n",
      "Epoch  9, Loss: 0.061739090699\n",
      "Epoch 10, Loss: 0.056378339411\n",
      "Epoch 11, Loss: 0.052204118593\n",
      "Epoch 12, Loss: 0.048964588991\n",
      "Epoch 13, Loss: 0.044467732421\n",
      "Epoch 14, Loss: 0.042177830430\n",
      "Epoch 15, Loss: 0.039575640976\n",
      "Epoch 16, Loss: 0.037469258580\n",
      "Epoch 17, Loss: 0.034605332395\n",
      "Epoch 18, Loss: 0.032409316632\n",
      "Epoch 19, Loss: 0.031168907345\n",
      "Epoch 20, Loss: 0.029228544062\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = LeNet5()\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Using Stochastic Gradient Descent with momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Number of epochs to train for\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        # Reset the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute and print loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize: update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}, Loss: {running_loss/len(trainloader):.12f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image file\n",
    "image_path = 'kaggle/let_net_5_sample_3.png'\n",
    "with open(image_path, 'rb') as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "\n",
    "# Convert bytes to a PIL Image\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "image = image.convert('L')  # Convert to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 8, expected: False\n",
      "Predicted probabilities: [[1.2930253e-01 1.0739955e-02 3.7719668e-03 8.3693722e-03 1.2009757e-01\n",
      "  8.9129739e-05 7.2757476e-03 6.1630011e-03 7.0629650e-01 7.8942021e-03]]\n"
     ]
    }
   ],
   "source": [
    "image_tensor = transform(image).float()\n",
    "\n",
    "# Unsqueeze to add a batch dimension ( C x H x W  ->  B x C x H x W )\n",
    "image_tensor = image_tensor.unsqueeze_(0)\n",
    "\n",
    "# Set the model to evaluation mod\n",
    "model.eval()\n",
    "\n",
    "# Pass the input through the model\n",
    "with torch.no_grad():  # Temporarily set all the requires_grad flag to false\n",
    "    output = model(image_tensor)\n",
    "\n",
    "# Interpret the predictions\n",
    "predicted_probabilities = torch.softmax(output, dim=1)\n",
    "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class.item()}, expected: {predicted_class.item() == 3}\")\n",
    "print(f\"Predicted probabilities: {predicted_probabilities.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
